import requests
from bs4 import BeautifulSoup
import pandas as pd

def scrap_to_csv():
    # Get user input for search query
    query = input("Enter the search query: ")

    # Get user input for the number of pages to scrape
    num_pages_to_scrape = int(input("Enter the number of pages to scrape: "))

    # Get user input for the output CSV filename without extension
    csv_filename = input("Enter the output CSV filename (default is 'output'): ") or "output"

    # Remove spaces from the filename and add the ".csv" extension
    csv_filename_modified = f"{csv_filename.replace(' ', '_')}.csv"

    data = []

    for page in range(1, num_pages_to_scrape + 1):
        params = {"q": query, "page": page}
        headers = {
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.54 Safari/537.36"
        }

        try:
            # Use a timeout to prevent potential network issues from causing long delays
            html = requests.get("https://wuzzuf.net/search/jobs/", params=params, headers=headers, timeout=30)
            html.raise_for_status()  # Raise an HTTPError for bad responses
        except requests.exceptions.RequestException as e:
            print(f"Error fetching page {page}: {e}")
            continue  # Skip to the next page on error

        soup = BeautifulSoup(html.text, "lxml")

        for result in soup.select(".css-1gatmva"):
            title = result.select_one(".css-m604qf .css-o171kl").text
            company_name = result.select_one(".css-17s97q8").text
            adding_time = result.select_one(".css-4c4ojb, .css-do6t5g").text
            location = result.select_one(".css-5wys0k").text
            employment = result.select_one(".css-1lh32fc").text

            data.append({
                "title": title,
                "company_name": company_name,
                "adding_time": adding_time,
                "location": location,
                "employment": employment,
            })

    df = pd.DataFrame(data)
    df.to_csv(csv_filename_modified, index=False)
    return df, csv_filename_modified

# Call the function to start the interactive scraping process
result_df, modified_filename = scrap_to_csv()

# Display a message indicating the original filename provided by the user
print(f"Result saved to {modified_filename.replace('.csv', '').replace('_', ' ')}")
